{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is to merge two counts data: APNIC and union\n",
    "\n",
    "Let me explain how two CSV files were created in emerald machine.\n",
    "\n",
    "## APNIC data: org_counts_apnic.csv\n",
    "\n",
    "+ Raw data files are located at: emerald:/data/bulk_apnic\n",
    "+ The processing can be done with: emerald:/var/opt/spam2/mapping/apnic/run_apnic.sh\n",
    "\n",
    "Briefly explaining the processing steps, \"run_get_ip_nb_as_count_from_apnic.py\" does the followings:\n",
    "+ first extract a gzipped file (YYYY-MM-DD-apnic.RPSL.db.gz) from above raw data folder\n",
    "+ in gzipped file, find blocks where \"descr\" field includes our focal companies' names \n",
    "+ if a block has \"aut-num\" field, then it is AS-related information\n",
    "+ if a block has \"inetnum\" field, then it is netblock information. With the netblock size, we can get the IP count\n",
    "+ all these AS, netblock, IP counts are stored as JSON files in emerald:/var/opt/spam2/mapping/apnics/data\n",
    "+ it takes an hour or so to process one gzipped file\n",
    "\n",
    "Once all the JSON files are ready, then \"make_csv_from_apnic_data.py\" does the followings:\n",
    "+ read JSON files from emerald:/var/opt/spam2/mapping/apnics/data\n",
    "+ create \"org_counts_apnic.csv\"\n",
    "\n",
    "\n",
    "## Union data: org_counts_union.csv\n",
    "\n",
    "+ Raw data files are located at: emerald:/data/bulk_cymru/raw\n",
    "+ \"emerald:/var/opt/spam2/mapping/parse_asn_netblock_mapping_from_cymru.py\" proceses the raw cymru files to get netblock-to-ASN mappings every day\n",
    "+ the resulting mappings are stored in \"emerald:/var/opt/spam2/mapping/union/pickle\" as Python pickle files\n",
    "+ \"emerald:/var/opt/spam2/mapping/apnic/run_get_ip_nb_as_count_from_union.py\" read those Picke files to generate \"org_counts_union.csv\" file\n",
    "\n",
    "\n",
    "## Now we can two CSV files are ready. Time to merge them!\n",
    "\n",
    "I used a few principles here:\n",
    "+ Find the months that both CSV files are covering\n",
    "+ For each month, get the larger IP/Netblock/AS counts from the two because each has partially coverage\n",
    "+ For example, \"union\" data cannot cover the cases where an org has netblocks but not ASN\n",
    "+ \"apnic\" data is created with string matching, it cannot cover the cases where netblocks' names are abbreviated\n",
    "+ For example, \"China National Petroleum Corporation\" was used in AS description but \"CNPC\" was used for netblocks\n",
    "\n",
    "## OK now let's merge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./org_counts_apnic.csv')\n",
    "df2 = pd.read_csv('./org_counts_union.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['201601', '201603', '201602', '201605', '201604', '201607', '201606', '201609', '201608', '201403', '201404', '201701', '201702', '201703', '201704', '201705', '201502', '201503', '201507', '201504', '201505', '201612', '201610', '201611'])\n"
     ]
    }
   ],
   "source": [
    "months1 = set()\n",
    "for col in df1.columns:\n",
    "    if col.count('_') == 0:\n",
    "        continue\n",
    "    months1.add(col.split('_')[-1])\n",
    "print months1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['201612', '201701', '201702', '201703', '201704', '201610', '201705', '201601', '201603', '201602', '201605', '201604', '201606', '201609', '201608', '201611'])\n"
     ]
    }
   ],
   "source": [
    "months2 = set()\n",
    "for col in df2.columns:\n",
    "    if col.count('_') == 0:\n",
    "        continue\n",
    "    months2.add(col.split('_')[-1])\n",
    "print months2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201601', '201602', '201603', '201604', '201605', '201606', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705']\n"
     ]
    }
   ],
   "source": [
    "inter = months1 & months2\n",
    "month_inter = sorted(list(inter))\n",
    "print month_inter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both union and APNIC data cover from 2016/01 to 2017/05, with an exception of 2016/07. \n",
    "\n",
    "With the assumption that AS/netblock mappings are not super dynamic, let's replace the missed 2016/07 records with 2016/06."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1004 Magna Automotive Technology and Service(Shanghai)Co Ltd',\n",
      " '1010 Founder Group',\n",
      " '1016 YunGang Technology Co Ltd',\n",
      " '1021 Beijing Capital Public Information Platform',\n",
      " '1023 Changhong IT information Products Co Ltd',\n",
      " '1025 Beijing Swifton inc',\n",
      " '1028 Beijing Haves Cinda Sci-Tech Development Co Ltd',\n",
      " '1033 Beijing Sinnet Technology Co Ltd',\n",
      " '1038 BeiJing Shocom Telecom Co Ltd',\n",
      " '1041 United e-Communicaiton (Beijing) S&T Ltd',\n",
      " '1042 Beijing Kaixinren Information Technology Company',\n",
      " '1045 BEIJING ZHONGGUANCUN SOFTWARE PARK DEVELOPMENT Co Ltd',\n",
      " '1047 BEIJING SHENZHOU GREATWALL COMMUNICATION',\n",
      " '1059 CITIC Ltd',\n",
      " '1069 Guangdong Hutong Broadband Network Co Ltd',\n",
      " '1097 Jiangxi Broadcasting and TV information Network',\n",
      " '1112 China Broadcasting TV Net',\n",
      " '1172 Guangzhou Tenmark Networks Technology Ltd',\n",
      " '1174 Easynet Global Services Asia',\n",
      " '1179 SHANGHAI Guangdian Electronics Group Co Ltd',\n",
      " '1185 Fumeiti Technology Co',\n",
      " '1196 GOIP-AULA-LIMITED',\n",
      " '1207 FoShan SHITONG Information Broadband Networks Co Ltd',\n",
      " '1211 Bodis LLC',\n",
      " '1217 The ChaYi Private Commercial High School',\n",
      " '1218 GCNet (Reach & Range Inc)',\n",
      " '1250 Price Waterhouse Taiwan',\n",
      " '1251 Seeder Computer Corporation Ltd',\n",
      " '1262 Diyixian.com (TW) Limited',\n",
      " '1276 Taiwan Internet Gateway',\n",
      " '1277 Trade-Van Informaiton Services Co',\n",
      " '1283 National Chiao Tung University',\n",
      " '1312 Veetime',\n",
      " '1314 Mobitai ISP Network Information Center',\n",
      " '1335 National Central University',\n",
      " '1343 Taiwan Semiconductor Manufactoring Company Ltd',\n",
      " '1354 PHOENIX CATV Co Ltd',\n",
      " '1360 AION TECHNOLOGIES Inc',\n",
      " '1365 PUMO NETWORK DIGITAL TECHNOLOGY Co Ltd',\n",
      " '1368 Fu Jen Catholic University',\n",
      " '1372 Vocom International Telecommunications Inc Taiwan',\n",
      " '1374 QUICKEN SCIENCE LTD',\n",
      " '1377 NameCentral',\n",
      " '1379 China Trust Commercial Bank',\n",
      " '1395 Shih-Hsin Cable Television Corporation',\n",
      " '1397 CHUAN KAI INTERNATIONAL Co Ltd',\n",
      " '1406 Macarius Global Services Pte Ltd',\n",
      " '1407 Agora Communications Pte Ltd',\n",
      " '1425 McKinsey & Company',\n",
      " '1438 General Motors Tech Center India Bangalore',\n",
      " '1447 ID.Safe Pte Ltd',\n",
      " '1451 Pacific Internet Malaysia',\n",
      " '1454 Woo Huiren',\n",
      " '1467 Sunflower Ltd',\n",
      " '1468 T-Systems International GmbH',\n",
      " '1476 Genentech',\n",
      " '1478 NetroNext Pte Ltd',\n",
      " '1479 United Techinologies Corp',\n",
      " '1484 Atlantic.Net Inc',\n",
      " '1497 Symbio Networks Pty Ltd',\n",
      " '1498 SIX Financial Information Singapore',\n",
      " '1518 Metlife Taiwan Taipei',\n",
      " '1573 SoHosting',\n",
      " '1588 Pacnet SG',\n",
      " '1629 Epsilon Telecommunications Ltd',\n",
      " '1631 Schenker Singapore (Pte) Ltd',\n",
      " '1642 Avago Technologies',\n",
      " '1644 ACE Insurance Singapore',\n",
      " '1645 Institute of Molecular and Cell Biology',\n",
      " '1655 DOCOMO interTouch - India Operation',\n",
      " '1663 University of NSW Asia',\n",
      " '1664 Limelight Networks Singapore',\n",
      " '1672 Salesforce.com Singapore Pte Ltd',\n",
      " '1675 Nepal Research and Education Network',\n",
      " '1680 Nucleus Connect Pte Ltd',\n",
      " '1681 Dimension Data AP Kaki Bukit Singapore',\n",
      " '1685 Global Foundries',\n",
      " '1686 Singapore Internet Exchange Ltd',\n",
      " '1694 VALE',\n",
      " '1700 MYHOSTING',\n",
      " '1706 Miller Ford Interactive',\n",
      " '1715 RADIOACTIVE PTE LTD',\n",
      " '1718 SG.GS',\n",
      " '1728 IIJ Global Soltuions Singapore Pte Ltd',\n",
      " '1730 CME Group Singapore Operations Pte Ltd',\n",
      " '1734 Ingram Micro Inc',\n",
      " '1740 PGi SG',\n",
      " '1756 CPF BOARD',\n",
      " '1758 X-TRA COMMUNICATION PTE LTD',\n",
      " '1763 AUCTORIZIUM PTE LTD',\n",
      " '1764 Cybersite Services Pte Ltd',\n",
      " '1767 Media Access International PTE LTD',\n",
      " '1781 Integrated Health Information Systems Pte Ltd',\n",
      " '1794 EXXON MOBIL CORPORATION',\n",
      " '1806 Infinity Supercorridor Sdn Bhd',\n",
      " '1810 JARING Communications Sdn Bhd',\n",
      " '1813 TPM Corp Berhad',\n",
      " '1820 Synergycloud Sdn Bhd',\n",
      " '1822 AS for DataOne(Malaysia)',\n",
      " '1823 Arcnet NTT MSC ISP',\n",
      " '1833 Broadband Service Provider',\n",
      " '1835 University Pendidikan Sultan Idris',\n",
      " '1836 OCE Sdn Bhd ISP',\n",
      " '1838 BMW Asia Technology Sdn Bhd',\n",
      " '1841 MIMOS R&D Malaysia',\n",
      " '1853 SHTECH City Broadband Service',\n",
      " '1860 Exa Bytes Network Sdn Bhd',\n",
      " '1869 MALAYSIA GENOME INSTITUTE',\n",
      " '1874 ModernOne Data Solutions Sdn Bhd',\n",
      " '1878 IX Telecom Network Operation Centre (NOC)',\n",
      " '1881 Xenial Broadband (Nationwide ISP)',\n",
      " '1882 Universiti Sultan Zainal Abidin',\n",
      " '1891 i-Berhad',\n",
      " '1894 ECS ICT BERHAD',\n",
      " '1902 PEERING1 SDN BHD',\n",
      " '1904 Universiti Tun Hussein Onn Malaysia',\n",
      " '1909 Exabytes Ecommerce Sdn Bhd',\n",
      " '1914 CET DEVELOPMENT SDN BHD',\n",
      " '1920 Fiber At Home City Networks Sdn Bhd',\n",
      " '1930 University Malaysia Pahang',\n",
      " '1931 Voizz Global Sdn Bhd',\n",
      " '1932 Telekom Malaysia',\n",
      " '1944 Virtela',\n",
      " '1972 UNIVERSITI TENAGA NASIONAL SDN BHD',\n",
      " '1974 PETRONAS ICT Sdn Bhd',\n",
      " '1977 D.A.H. Private Bank',\n",
      " '1983 SUDU.CN',\n",
      " '1985 2012 Limited / Netfront',\n",
      " '2014 8Lian Technology Co Ltd',\n",
      " '2044 Asia Web Service Ltd',\n",
      " '2045 Asiamax Technology Limited VPN Service Provider Hong Kong',\n",
      " '2049 Austreme',\n",
      " '2056 BBIX Inc',\n",
      " '2058 Beijing Blan Star Technology Co Ltd',\n",
      " '2069 Beijing Guanghuan Telecom Group',\n",
      " '2080 Beijing Qihu Technology Co Ltd',\n",
      " '2096 BodyTrace Limited',\n",
      " '2327 China National Institute of Standardization',\n",
      " '2344 China Telecom (Group)',\n",
      " '2353 China Telecom Corporation Limited',\n",
      " '2422 Citic Telecom International (Data) Ltd',\n",
      " '2469 CommuniLink Internet Ltd ',\n",
      " '2470 ComNet Telecom International Ltd',\n",
      " '2487 Donghwa Telecom Co Ltd',\n",
      " '2519 Forest Eternal Communication Tech Co Ltd',\n",
      " '2524 FOREX CAPITAL MARKETS/FXCM Asia Limited',\n",
      " '2532 GLOBAL ESOLUTIONS HK LTD ',\n",
      " '2533 Global ICT Solutions (ShangHai) CO LTD',\n",
      " '2536 GlobeCast Hong Kong',\n",
      " '2540 Grey Group',\n",
      " '2543 Harbin Economic-technological Development Zone',\n",
      " '2558 HKCSL GPRS NETWORK',\n",
      " '2588 Howtimefly (BeiJing) Info tech Ltd',\n",
      " '2603 Hutchison Telephone Co Ltd/ Hutchison Telecommunications Hong Kong Holdings Limited',\n",
      " '2615 InfoMove Solutions Limited',\n",
      " '2643 Kantone Paging Co Ltd',\n",
      " '2644 KDD HONG KONG LIMITED',\n",
      " '2665 MAGIC VANGUARD LIMITED',\n",
      " '2675 Microsoft Online',\n",
      " '2694 Network Infinity Technologies Limited',\n",
      " '2753 QI Ltd',\n",
      " '2755 QingDao WangXin Telcom Co Ltd',\n",
      " '2772 Schweizerische Rueckversicherungs-Gesellschaft AG',\n",
      " '2813 Springfield NOC',\n",
      " '2829 Tai Fook Securities Group HK',\n",
      " '2830 TAIWOKAN TECHNOLOGY Co Ltd',\n",
      " '2831 TECHNOWORKS AUSTRALIA',\n",
      " '2834 Telekomunikasi Indonesia International Hong Kong',\n",
      " '2856 TianJin ERENB Technology Development Co Ltd',\n",
      " '2861 TOURICO HOLIDAYS HONG KONG LIMITED',\n",
      " '2867 TVB.COM LIMITED',\n",
      " '2870 UnionFriend Network information service Co Ltd',\n",
      " '2871 University of Macau',\n",
      " '2887 WebWeb',\n",
      " '2891 WING HANG BANK LIMITED',\n",
      " '2894 WISERS INFORMATION LIMITED ',\n",
      " '2902 Yahoo China Datacenter',\n",
      " '2910 Yaren Lam']\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "metrics = dict()\n",
    "metrics['ip'] = []\n",
    "metrics['nb'] = []\n",
    "metrics['as'] = []\n",
    "\n",
    "# construct dictionary for later merged dataframe\n",
    "counts = dict()\n",
    "for month in inter:\n",
    "    counts['ip{}'.format(month)] = []\n",
    "    counts['nb{}'.format(month)] = []\n",
    "    counts['as{}'.format(month)] = []\n",
    "    \n",
    "for index, row in df1.iterrows():\n",
    "    #print row['DossierID'], row['org']\n",
    "    this_counts = dict()\n",
    "    this_counts['ip'] = []\n",
    "    this_counts['nb'] = []\n",
    "    this_counts['as'] = []\n",
    "    for month in month_inter:\n",
    "        #print month,\n",
    "        for metric in metrics:\n",
    "            apnic_count = row['{}_apnic_{}'.format(metric, month)]\n",
    "            union_count = df2.ix[index]['{}_union_{}'.format(metric, month)]\n",
    "            larger_count = max(apnic_count, union_count)\n",
    "            this_counts[metric].append(larger_count)\n",
    "            \n",
    "            counts['{}{}'.format(metric, month)].append(larger_count)\n",
    "            \n",
    "            #if apnic_count ==0 and union_count == 0:\n",
    "            #    #metrics[metric] += 1\n",
    "            #print apnic_count, union_count, (apnic_count==union_count),\n",
    "        #print\n",
    "    for metric in this_counts:\n",
    "        if sum(this_counts[metric]) == 0:\n",
    "            metrics[metric].append(str(row['DossierID']) + ' ' + row['org'])\n",
    "        #print\n",
    "        \n",
    "\n",
    "pprint(metrics['ip'])\n",
    "print len(metrics['ip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the list of 178 organizations without any netblock/IP information. At least we made a big improvement from 339 zero-IP orgs from previous data. Hopefully we have enough samples now!\n",
    "\n",
    "## now let's make the merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['201601', '201602', '201603', '201604', '201605', '201606', '201608', '201609', '201610', '201611', '201612', '201701', '201702', '201703', '201704', '201705']\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_excel('./for_randomization_170426.xlsx')\n",
    "\n",
    "metrics = ['ip', 'nb', 'as']\n",
    "print month_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DossierID</th>\n",
       "      <th>org</th>\n",
       "      <th>IsChinese</th>\n",
       "      <th>hsic</th>\n",
       "      <th>Industry Description</th>\n",
       "      <th>Country</th>\n",
       "      <th>hasFacebook</th>\n",
       "      <th>hasTwitter</th>\n",
       "      <th>hasWeibo</th>\n",
       "      <th>hasWeChat</th>\n",
       "      <th>...</th>\n",
       "      <th>pv201612</th>\n",
       "      <th>pv201701</th>\n",
       "      <th>pv201702</th>\n",
       "      <th>pv201703</th>\n",
       "      <th>ip201704</th>\n",
       "      <th>ip201705</th>\n",
       "      <th>nb201704</th>\n",
       "      <th>nb201705</th>\n",
       "      <th>as201704</th>\n",
       "      <th>as201705</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>LiaoHe Oilfield Telecommunication Company</td>\n",
       "      <td>Y</td>\n",
       "      <td>631200</td>\n",
       "      <td>Web portals</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49152</td>\n",
       "      <td>49152</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Beijing Expo Cloud Technology Co Ltd</td>\n",
       "      <td>Y</td>\n",
       "      <td>631100</td>\n",
       "      <td>data processing, hosting and related activities</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Shenzhen Aosida Communication Co Ltd</td>\n",
       "      <td>Y</td>\n",
       "      <td>611000</td>\n",
       "      <td>Telecommunications network operation</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183296</td>\n",
       "      <td>183296</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Magna Automotive Technology and Service(Shangh...</td>\n",
       "      <td>Y</td>\n",
       "      <td>290000</td>\n",
       "      <td>Body assembly of motor vehicles</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Guizhou Wing Cloud High Technology Ltd</td>\n",
       "      <td>Y</td>\n",
       "      <td>631100</td>\n",
       "      <td>Data processing, hosting and related activities</td>\n",
       "      <td>CN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67584</td>\n",
       "      <td>67584</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DossierID                                                org IsChinese  \\\n",
       "0       1001          LiaoHe Oilfield Telecommunication Company         Y   \n",
       "1       1002               Beijing Expo Cloud Technology Co Ltd         Y   \n",
       "2       1003               Shenzhen Aosida Communication Co Ltd         Y   \n",
       "3       1004  Magna Automotive Technology and Service(Shangh...         Y   \n",
       "4       1005             Guizhou Wing Cloud High Technology Ltd         Y   \n",
       "\n",
       "     hsic                             Industry Description Country  \\\n",
       "0  631200                                      Web portals      CN   \n",
       "1  631100  data processing, hosting and related activities      CN   \n",
       "2  611000            Telecommunications network operation       CN   \n",
       "3  290000                 Body assembly of motor vehicles       CN   \n",
       "4  631100  Data processing, hosting and related activities      CN   \n",
       "\n",
       "   hasFacebook  hasTwitter  hasWeibo  hasWeChat    ...     pv201612  pv201701  \\\n",
       "0            0           0         0          1    ...            0         0   \n",
       "1            0           0         0          0    ...            6         0   \n",
       "2            0           0         0          0    ...            0         0   \n",
       "3            0           0         1          1    ...            0         0   \n",
       "4            0           0         0          0    ...            0         0   \n",
       "\n",
       "   pv201702  pv201703  ip201704  ip201705  nb201704  nb201705  as201704  \\\n",
       "0         0         0     49152     49152         5         5         1   \n",
       "1         0         0       512       512         2         2         1   \n",
       "2         0         0    183296    183296        14        14         1   \n",
       "3         0         0         0         0         0         0         1   \n",
       "4         0         0     67584     67584         3         3         2   \n",
       "\n",
       "   as201705  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         2  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    for month in month_inter:\n",
    "        new_df['{}{}'.format(metric, month)] = counts['{}{}'.format(metric, month)]\n",
    "        # let's fill in 2016/07 with 2016/06\n",
    "        if month == '201606':\n",
    "            new_df['{}201607'.format(metric)] = counts['{}{}'.format(metric, month)]\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DossierID</th>\n",
       "      <th>hsic</th>\n",
       "      <th>hasFacebook</th>\n",
       "      <th>hasTwitter</th>\n",
       "      <th>hasWeibo</th>\n",
       "      <th>hasWeChat</th>\n",
       "      <th>hasTencentWeibo</th>\n",
       "      <th>ip201512</th>\n",
       "      <th>ip201601</th>\n",
       "      <th>ip201602</th>\n",
       "      <th>...</th>\n",
       "      <th>pv201612</th>\n",
       "      <th>pv201701</th>\n",
       "      <th>pv201702</th>\n",
       "      <th>pv201703</th>\n",
       "      <th>ip201704</th>\n",
       "      <th>ip201705</th>\n",
       "      <th>nb201704</th>\n",
       "      <th>nb201705</th>\n",
       "      <th>as201704</th>\n",
       "      <th>as201705</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1.262000e+03</td>\n",
       "      <td>1.262000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1.262000e+03</td>\n",
       "      <td>1.262000e+03</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "      <td>1262.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1910.603803</td>\n",
       "      <td>626104.491284</td>\n",
       "      <td>0.480190</td>\n",
       "      <td>0.342314</td>\n",
       "      <td>0.267829</td>\n",
       "      <td>0.240095</td>\n",
       "      <td>0.126783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.793416e+05</td>\n",
       "      <td>4.757112e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>233.512678</td>\n",
       "      <td>62.649762</td>\n",
       "      <td>195.183043</td>\n",
       "      <td>117.457211</td>\n",
       "      <td>4.833362e+05</td>\n",
       "      <td>4.808875e+05</td>\n",
       "      <td>35.610143</td>\n",
       "      <td>35.899366</td>\n",
       "      <td>1.673534</td>\n",
       "      <td>1.676704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>587.160233</td>\n",
       "      <td>119032.960562</td>\n",
       "      <td>0.499805</td>\n",
       "      <td>0.474672</td>\n",
       "      <td>0.443003</td>\n",
       "      <td>0.427310</td>\n",
       "      <td>0.332862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.279871e+06</td>\n",
       "      <td>5.281042e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2370.397172</td>\n",
       "      <td>887.293733</td>\n",
       "      <td>2882.801924</td>\n",
       "      <td>1705.388801</td>\n",
       "      <td>5.385209e+06</td>\n",
       "      <td>5.345345e+06</td>\n",
       "      <td>238.915555</td>\n",
       "      <td>242.535118</td>\n",
       "      <td>4.166013</td>\n",
       "      <td>4.167403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1401.500000</td>\n",
       "      <td>611000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.120000e+02</td>\n",
       "      <td>2.720000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.560000e+02</td>\n",
       "      <td>2.560000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1825.500000</td>\n",
       "      <td>620200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.048000e+03</td>\n",
       "      <td>2.048000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.048000e+03</td>\n",
       "      <td>2.048000e+03</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2531.500000</td>\n",
       "      <td>639100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.638400e+04</td>\n",
       "      <td>1.638400e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.708800e+04</td>\n",
       "      <td>1.728000e+04</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2922.000000</td>\n",
       "      <td>960299.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344774e+08</td>\n",
       "      <td>1.351965e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>57849.000000</td>\n",
       "      <td>21765.000000</td>\n",
       "      <td>69434.000000</td>\n",
       "      <td>43868.000000</td>\n",
       "      <td>1.397320e+08</td>\n",
       "      <td>1.380352e+08</td>\n",
       "      <td>5516.000000</td>\n",
       "      <td>5555.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DossierID           hsic  hasFacebook   hasTwitter     hasWeibo  \\\n",
       "count  1262.000000    1262.000000  1262.000000  1262.000000  1262.000000   \n",
       "mean   1910.603803  626104.491284     0.480190     0.342314     0.267829   \n",
       "std     587.160233  119032.960562     0.499805     0.474672     0.443003   \n",
       "min    1001.000000   50000.000000     0.000000     0.000000     0.000000   \n",
       "25%    1401.500000  611000.000000     0.000000     0.000000     0.000000   \n",
       "50%    1825.500000  620200.000000     0.000000     0.000000     0.000000   \n",
       "75%    2531.500000  639100.000000     1.000000     1.000000     1.000000   \n",
       "max    2922.000000  960299.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         hasWeChat  hasTencentWeibo  ip201512      ip201601      ip201602  \\\n",
       "count  1262.000000      1262.000000    1262.0  1.262000e+03  1.262000e+03   \n",
       "mean      0.240095         0.126783       0.0  4.793416e+05  4.757112e+05   \n",
       "std       0.427310         0.332862       0.0  5.279871e+06  5.281042e+06   \n",
       "min       0.000000         0.000000       0.0  0.000000e+00  0.000000e+00   \n",
       "25%       0.000000         0.000000       0.0  5.120000e+02  2.720000e+02   \n",
       "50%       0.000000         0.000000       0.0  2.048000e+03  2.048000e+03   \n",
       "75%       0.000000         0.000000       0.0  1.638400e+04  1.638400e+04   \n",
       "max       1.000000         1.000000       0.0  1.344774e+08  1.351965e+08   \n",
       "\n",
       "          ...           pv201612      pv201701      pv201702      pv201703  \\\n",
       "count     ...        1262.000000   1262.000000   1262.000000   1262.000000   \n",
       "mean      ...         233.512678     62.649762    195.183043    117.457211   \n",
       "std       ...        2370.397172    887.293733   2882.801924   1705.388801   \n",
       "min       ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%       ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%       ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%       ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max       ...       57849.000000  21765.000000  69434.000000  43868.000000   \n",
       "\n",
       "           ip201704      ip201705     nb201704     nb201705     as201704  \\\n",
       "count  1.262000e+03  1.262000e+03  1262.000000  1262.000000  1262.000000   \n",
       "mean   4.833362e+05  4.808875e+05    35.610143    35.899366     1.673534   \n",
       "std    5.385209e+06  5.345345e+06   238.915555   242.535118     4.166013   \n",
       "min    0.000000e+00  0.000000e+00     0.000000     0.000000     1.000000   \n",
       "25%    2.560000e+02  2.560000e+02     1.000000     1.000000     1.000000   \n",
       "50%    2.048000e+03  2.048000e+03     3.000000     3.000000     1.000000   \n",
       "75%    1.708800e+04  1.728000e+04    12.000000    12.000000     1.000000   \n",
       "max    1.397320e+08  1.380352e+08  5516.000000  5555.000000   119.000000   \n",
       "\n",
       "          as201705  \n",
       "count  1262.000000  \n",
       "mean      1.676704  \n",
       "std       4.167403  \n",
       "min       1.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max     119.000000  \n",
       "\n",
       "[8 rows x 141 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.to_excel('./for_randomization_170509.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this Excel file was created, I did some manual column reordering for beautification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:INSY5378]",
   "language": "python",
   "name": "conda-env-INSY5378-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
